{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77802ea-3f79-4e33-abf3-b94862de7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig, \n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdda2283-4720-48b6-bf2a-4f182a53c952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4fb89653de4a38b221cecd169a7c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3809cbd35ef1479c8439b8211fc84c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aime_2024_problems.parquet:   0%|          | 0.00/37.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea3573e38ec448eb8aede1591b079c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aime24 = load_dataset(\"Maxwell-Jia/AIME_2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a20c015-5563-4afb-bf29-183a3e584e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'Problem', 'Solution', 'Answer'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aime24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88baec39-23cf-4689-b5a2-5939bbf8ef2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': '2024-II-6',\n",
       " 'Problem': \"Alice chooses a set $A$ of positive integers. Then Bob lists all finite nonempty sets $B$ of positive integers with the property that the maximum element of $B$ belongs to $A$. Bob's list has 2024 sets. Find the sum of the elements of A.\",\n",
       " 'Solution': \"Let $k$ be one of the elements in Alice's set $A$ of positive integers. The number of sets that Bob lists with the property that their maximum element is $k$ is $2^{k-1}$, since every positive integer less than $k$ can be in the set or out. Thus, for the number of sets Bob has listed to be 2024, we want to find a sum of unique powers of two that can achieve this. 2024 is equal to $2^{10} + 2^9 + 2^8 + 2^7 + 2^6 + 2^5 + 2^3$. We must increase each power by 1 to find the elements in set $A$, which are $(11, 10, 9, 8, 7, 6, 4)$. Add these up to get $55$.\",\n",
       " 'Answer': 55}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aime24['train'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22279a6b-264d-4f60-bc5e-f8d4614d9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate empty csv to be filled manually\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e898a-7f74-4278-bfd6-7d66604ff69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccc7402-c9aa-4714-903e-ef3d2b2d65a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "560c09ce-0eb0-454c-92cc-4efc06433cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337b4aaa-a9a3-4f31-8e2f-8ec5be877943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903a9174ab9e4744bd014b6ac80cf93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4474676d-8794-4022-8f2c-22bf94946c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"do_sample\": true,\n",
       "  \"eos_token_id\": [\n",
       "    151645,\n",
       "    151643\n",
       "  ],\n",
       "  \"pad_token_id\": 151643,\n",
       "  \"temperature\": 0.6,\n",
       "  \"top_k\": 20,\n",
       "  \"top_p\": 0.95\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "593c59de-6e07-4fb9-bcc4-7641a9292e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"Please reason step by step, and put your final answer within \\boxed{}. \" \n",
    "prompt2 = \"Answer the following question, and put your final answer within \\boxed{}. \"\n",
    "\n",
    "prompt = prompt1 + aime24['train'][3]['Problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24f0c30d-5528-491b-9738-6f083a71f369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Please reason step by step, and put your final answer within \\x08oxed{}. Alice and Bob play the following game. A stack of $n$ tokens lies before them. The players take turns with Alice going first. On each turn, the player removes either $1$ token or $4$ tokens from the stack. Whoever removes the last token wins. Find the number of positive integers $n$ less than or equal to $2024$ for which there exists a strategy for Bob that guarantees that Bob will win the game regardless of Alice's play.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ba3ea8a-5d75-47a8-a00a-32b667ec0778",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0820adf-d5d6-436f-afa6-338e9b3a0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5722f032-c9b4-416f-8f53-3f53504515db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c5e33-4f15-48ca-bddf-55eee305c8f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "print(\"answer:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecaf6cfb-b719-4f2d-bc6f-a96dd7cf4677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'116'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box = 'boxed{'\n",
    "box_begin = content.find(box)\n",
    "box_end = box_begin + content[box_begin:].find('}')\n",
    "content[box_begin+len(box):box_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6722f-7f45-497c-a3f8-abefd3b616ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a271127b-cdab-48f2-a1c0-ddaaeb07abf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24376da8c122435c87ff94ae976e6494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-Math-7B-Instruct\"\n",
    "device = \"cuda:6\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cuda:6\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# prompt = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27dfe0ab-b5ff-4e31-9f7d-72c1d0776174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoT\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Please reason step by step, and put your final answer within \\boxed{}.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abedb609-e8d0-4b0f-b8c5-42effc4acf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=6)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "610f132c-1dc3-4ef5-ada7-799a99349d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cda2914a-6a80-4431-aa42-4487bc36259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "content = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49d80268-7620-4091-9b3b-3d1cacf39559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' position \\\\( W \\\\) because the player can remove the last token.\\n- \\\\( n = 2 \\\\) is a winning position \\\\( W \\\\) because the player can remove 1 token and leave the opponent with 1 token.\\n- \\\\( n = 3 \\\\) is a winning position \\\\( W \\\\) because the player can remove 1 token and leave the opponent with 2 tokens.\\n- \\\\( n = 4 \\\\) is a losing position \\\\( L \\\\) because the player can only remove 1 or 4 tokens, leaving the opponent with 3 or 0 tokens, both of which are winning positions.\\n\\nFor \\\\( n \\\\geq 5 \\\\), we can determine the position by considering the possible moves:\\n- If \\\\( n \\\\) is a winning position, then there exists a move to a losing position.\\n- If \\\\( n \\\\) is a losing position, then all possible moves lead to a winning position.\\n\\nUsing this, we can extend the pattern:\\n- \\\\( n = 5 \\\\) is a winning position \\\\( W \\\\) because the player can remove 1 token and leave the opponent with 4 tokens.\\n- \\\\( n = 6 \\\\) is a winning position \\\\( W \\\\) because the player can remove 1 token and leave the opponent with 5 tokens.\\n- \\\\( n = 7 \\\\) is a winning position \\\\( W \\\\) because the player can remove 1 token and leave the opponent with 6 tokens.\\n- \\\\( n = 8 \\\\) is a losing position \\\\( L \\\\) because the player can only remove 1 or 4 tokens, leaving the opponent with 7 or 4 tokens, both of which are winning positions.\\n\\nWe observe that the pattern repeats every 5 numbers: \\\\( L, W, W, W, L \\\\).\\n\\nTo find the number of losing positions \\\\( L \\\\) less than or equal to 2024, we need to count the multiples of 5 within this range. The multiples of 5 are:\\n\\\\[ 5, 10, 15, \\\\ldots, 2020 \\\\]\\n\\nThis is an arithmetic sequence where the first term \\\\( a = 5 \\\\) and the common difference \\\\( d = 5 \\\\). The \\\\( k \\\\)-th term of the sequence is given by:\\n\\\\[ a_k = a + (k-1)d \\\\]\\n\\nWe set \\\\( a_k \\\\leq 2024 \\\\) to find the largest \\\\( k \\\\):\\n\\\\[ 5 + (k-1) \\\\cdot 5 \\\\leq 2024 \\\\]\\n\\\\[ 5k \\\\leq 2024 \\\\]\\n\\\\[ k \\\\leq \\\\frac{2024}{5} \\\\]\\n\\\\[ k \\\\leq 404.8 \\\\]\\n\\nSince \\\\( k \\\\) must be an integer, the largest possible value for \\\\( k \\\\) is 404. Therefore, there are 404 multiples of 5 less than or equal to 2024.\\n\\nThus, the number of positive integers \\\\( n \\\\) less than or equal to 2024 for which Bob has a winning strategy is:\\n\\\\[\\n\\\\boxed{404}\\n\\\\]'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95b4e2a2-77fa-4407-b731-0178d7c2cf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'404'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box = 'boxed{'\n",
    "box_begin = content.find(box)\n",
    "box_end = box_begin + content[box_begin:].find('}')\n",
    "content[box_begin+len(box):box_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991869c-342f-4f34-a2fe-2d0055362ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
